Model: llava-13b
Macro avg: 0.5625
All accuracies: [0, 1.0, 1.0, 0, 1.0, 0, 0, 0, 1.0, 1.0, 0, 1.0, 0, 1.0, 1.0, 1.0]
Macro avg bleus: 0.16268345713131588
All bleus: [0.059234887775909226, 0.08856148855400955, 0.4613501813258397, 0.4532182345411428, 0.06433562658187233, 0.20579830217101064, 0.1415794572998021, 0.2466918414831204, 0.14794534429106182, 0.11180339887498951, 0.07585826061362602, 0.05947347426475931, 0.13535365043848246, 0.30665073827811323, 0.045080427607314975, 3.555624432523085e-155]
Macro avg rogues: 0.32138755308375255
All rogues: [0.1629629600395062, 0.21052631211966763, 0.5609756047560976, 0.568181813184401, 0.25862068590517245, 0.3783783733929877, 0.42592592191358036, 0.499999995181406, 0.3296703251781186, 0.25974025498397707, 0.19672130812147276, 0.20224718820855958, 0.2698412652494331, 0.5192307643491124, 0.21917807944454873, 0.07999999731200008]
Macro similarities: 0.6496078092604876
All similarities: [0.7190806865692139, 0.7576528787612915, 0.787147045135498, 0.7970366477966309, 0.37549710273742676, 0.4113135039806366, 0.8560584783554077, 0.8584956526756287, 0.6376564502716064, 0.4569663107395172, 0.6979959011077881, 0.6838857531547546, 0.6273840069770813, 0.8950323462486267, 0.492404043674469, 0.3401181399822235]